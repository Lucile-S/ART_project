{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "_WCGAN_Painting_by_GENRE_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMj5w4RXhbPkDdS+EgWmWP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucile-S/ART_project/blob/main/WCGAN_Painting_by_GENRE_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG-hPpemlNeJ"
      },
      "source": [
        "## packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787YmqKYapok",
        "outputId": "dcebf2b4-6db6-4c29-b543-47f144627204"
      },
      "source": [
        "!pip install tensorboard\n",
        "!pip install \"tqdm==4.43.0\"\n",
        "import os\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "from glob import iglob\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import copy\n",
        "import urllib\n",
        "import time\n",
        "from datetime import datetime\n",
        "import collections \n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.40.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Collecting tqdm==4.43.0\n",
            "  Downloading tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 2.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.43.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRQpcO4FxdIf"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRipMatbxdV4"
      },
      "source": [
        "class Artist(object):\n",
        "    \"\"\"\n",
        "    Artist Object\n",
        "    \"\"\"\n",
        "    def __init__(self, folder_path:str, label_id=None ):\n",
        "        self._path = folder_path.replace('\\\\',r'/')\n",
        "        self._label_id = label_id\n",
        "\n",
        "    @property\n",
        "    def folder_name(self):\n",
        "        return os.path.basename(self._path)\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "      return os.path.basename(self._path).replace('-',' ').title()\n",
        "\n",
        "    @property\n",
        "    def path(self):\n",
        "        return self._path\n",
        "    \n",
        "    @property\n",
        "    def painting_paths(self):\n",
        "        return list(iglob(self._path + '/*.jpg'))\n",
        "\n",
        "    @property\n",
        "    def painting_titles(self):\n",
        "        return [ os.path.basename(painting_path).replace('.jpg','').replace('-',' ').capitalize() for painting_path in iglob(self._path + '/*.jpg') ]\n",
        "\n",
        "    @property\n",
        "    def painting_nb(self):\n",
        "      return len(list(iglob(self._path + '/*.jpg')))\n",
        "\n",
        "    @property\n",
        "    def label(self):\n",
        "        # just one label_id\n",
        "        if isinstance(self._label_id, int):\n",
        "            return self._label_id\n",
        "        # sample associated with multiple labels\n",
        "        else:\n",
        "            return [int(label_id) for label_id in self._label_id]\n",
        "  \n",
        "\n",
        "class Painting(object):\n",
        "    \"\"\"\n",
        "    Painting Object\n",
        "    \"\"\"\n",
        "    def __init__(self, painting_path:str):\n",
        "        self._path = painting_path.replace('\\\\',r'/')\n",
        "        self._json = self._path.replace('.jpg','.json')\n",
        "        self._data = open_json_file(self._json)\n",
        "        self._filename = os.path.basename(self._json).replace('.json','')\n",
        "        self._key = list(self._data.keys())[0]\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "      return  self._data\n",
        "\n",
        "\n",
        "    @property\n",
        "    def filename(self):\n",
        "      return  self._filename\n",
        "\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "      return  self._data[self._key]['Name']\n",
        "\n",
        "    @property\n",
        "    def artist(self):\n",
        "      return  self._data[self._key]['Artist']\n",
        "\n",
        "\n",
        "    @property\n",
        "    def date(self):\n",
        "      return self._data[self._key]['Date']\n",
        "  \n",
        "  \n",
        "    @property\n",
        "    def style(self):\n",
        "      return self._data[self._key]['Style']\n",
        "    \n",
        "    @property\n",
        "    def genre(self):\n",
        "      return self._data[self._key]['Genre']\n",
        "\n",
        "        \n",
        "    @property\n",
        "    def tags(self):\n",
        "      return self._data[self._key]['Tags']\n",
        "\n",
        "class Art_Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image_paths (list): list of image paths.\n",
        "        df (pandas dataframe) : dataframe containning images names and encoding labels \n",
        "        classes (list): list of classes.\n",
        "        transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_paths:list, labels:list, transform =None):\n",
        "      self.image_paths = image_paths\n",
        "      self.labels = labels \n",
        "      self.transform  = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #print(f'--- GET ITEM  # {index} ---')\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path).convert('RGB') \n",
        "        label =  self.labels[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label, image_path\n",
        "\n",
        "\n",
        "class CustomResize(object):\n",
        "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "\n",
        "    def __call__(self, img):\n",
        "        old_size = img.size  # old_size[0] is in (width, height) format\n",
        "\n",
        "        ratio = float(self.size)/min(old_size)\n",
        "        new_size = tuple([int(x * ratio) for x in old_size])\n",
        "\n",
        "        return img.resize(new_size, resample=self.interpolation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tnecDwrac3a"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4PdSUe1acUj"
      },
      "source": [
        "## utils\n",
        "\n",
        "def MakeDir(DIR:str) -> None:\n",
        "    try:\n",
        "        if not os.path.exists(DIR):\n",
        "            os.makedirs(DIR)\n",
        "    except OSError as err:\n",
        "        print(err)\n",
        "        pass\n",
        "\n",
        "def show_batch(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    try: \n",
        "      image_unflat = image_tensor.detach().cpu()\n",
        "    except: \n",
        "      image_unflat = image_tensor\n",
        "      \n",
        "    plt.figure(figsize = (12,12))\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "def gradient_penalty(critic, labels, real, fake, device=\"cpu\"):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
        "\n",
        "    # Calculate critic scores\n",
        "    mixed_scores = critic(interpolated_images, labels)\n",
        "\n",
        "    # Take the gradient of the scores with respect to the images\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=interpolated_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"celeba_wgan_gp.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, gen, disc):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    gen.load_state_dict(checkpoint['gen'])\n",
        "    disc.load_state_dict(checkpoint['disc'])\n",
        "    \n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1,64, 64), nrow=5, show=True):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "def save_samples(index, epoch, fixed_noise, fixed_labels,  stats , sample_dir = '.', resize_size=128, show=True):\n",
        "    fake_images = gen(fixed_noise, fixed_labels)\n",
        "    fake_fname = f'Wcgan-bygenre-generated-images-{index:0=5d}-epoch-{epoch:0=4d}.jpg'\n",
        "    save_image(denorm(transforms.Resize(resize_size)(fake_images), stats).clamp(0, 1), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(denorm(fake_images.detach().cpu(), stats), nrow=8).permute(1, 2, 0).squeeze())\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def denorm(img_tensors, stats):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kHkDgPia0-t"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCa8YfICatX4"
      },
      "source": [
        "\"\"\"\n",
        "Discriminator and Generator implementation from DCGAN paper\n",
        "\"\"\"\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels_img, features_d, num_classes,  img_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.channels_img = channels_img\n",
        "        self.disc = nn.Sequential(\n",
        "            # input: N x channels_img x 64 x 64\n",
        "            nn.Conv2d(self.channels_img + num_classes , features_d, kernel_size=4, stride=2, padding=1),\n",
        "            #nn.Conv2d(self.channels_img +1 , features_d, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
        "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
        "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
        "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
        "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
        "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes, num_classes)\n",
        "        #self.embed = nn.Embedding(num_classes, img_size*img_size)\n",
        "\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
        "            ),\n",
        "            nn.InstanceNorm2d(out_channels, affine=True),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        #embedding =  self.embed(labels).view(labels.shape[0], self.channels_img, self.img_size, self.img_size) # it's like an additional channel ; # N x C x H x W\n",
        "        embedding =   self.embed(labels)[:,:,None,None].repeat(1, 1, self.img_size, self.img_size) # N x N_classes x IMG_SIZE x IMG_siSE\n",
        "       \n",
        "        x = torch.cat([x, embedding], dim=1)\n",
        "\n",
        "        return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, channels_noise, channels_img, features_g, num_classes, img_size, embed_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: N x channels_noise x 1 x 1\n",
        "            self._block(channels_noise + embed_size, features_g * 16, 4, 1, 0),  # img: 4x4\n",
        "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
        "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
        "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
        "            nn.ConvTranspose2d(\n",
        "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
        "            ),\n",
        "            # Output: N x channels_img x 64 x 64\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes,embed_size)\n",
        "        #self.embed = nn.Embedding(num_classes,num_classes)\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embedding = self.embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        x = torch.cat([x, embedding], dim=1)\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def initialize_weights(model):\n",
        "    # Initializes weights according to the DCGAN paper\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmwi_nKjuC8K"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGERJPrnuB-Q",
        "outputId": "388bce6e-d680-414c-d948-33a85b36e6ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyU6_GONxGTs",
        "outputId": "d6fad71c-2c75-4b59-f820-5d0691c7f498"
      },
      "source": [
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/MyDrive/ /mydrive\n",
        "\n",
        "%cd mydrive\n",
        "\n",
        "!ls /mydrive/GAN/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'mydrive'\n",
            "/content\n",
            "Data  generated  logs  Models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw3Jmlp5AnH2",
        "outputId": "e87d8c48-aed1-417b-9657-8a855816149a"
      },
      "source": [
        "!ls /mydrive/GAN/Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "amedeo-modigliani      gustav-klimt\t\t      pierre-auguste-renoir\n",
            "arnold-bocklin\t       henri-matisse\t\t      piet-mondrian\n",
            "artemisia-gentileschi  henri-rousseau\t\t      rembrandt\n",
            "Artists.csv\t       john-james-audubon\t      sandro-botticelli\n",
            "claude-monet\t       joseph-mallord-william-turner  theophile-steinlen\n",
            "david-burliuk\t       katsushika-hokusai\t      vassily-kandinsky\n",
            "edward-hopper\t       pablo-picasso\t\t      vincent-van-gogh\n",
            "ernst-ludwig-kirchner  Paintings.csv\t\t      zdzislaw-beksinski\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lHXaegyxkJy",
        "outputId": "aeb84d31-3a0a-4bd7-d8bc-79affb353d7f"
      },
      "source": [
        "# -----------#\n",
        "#    DATA    #\n",
        "# -----------#\n",
        "BY_GENRE = True\n",
        "BY_ARTIST= False\n",
        "\n",
        "# -- image Directory \n",
        "DIR = '/mydrive/GAN' \n",
        "img_DIR = os.path.join(DIR,'Data')\n",
        "artist_paths =  [ artist_path for artist_path  in iglob(img_DIR +'/*') if os.path.isdir(artist_path)]\n",
        "# -- list of Artist instance\n",
        "ARTISTS  = [Artist(artist_path) for artist_path in artist_paths]\n",
        "print(f'There are {len(artist_paths)} artists')\n",
        "print(artist_paths)\n",
        "\n",
        "artist_csv_path = os.path.join(img_DIR, 'Artists.csv')\n",
        "df_artist = pd.read_csv(artist_csv_path, sep=\";\")\n",
        "painting_csv_path = os.path.join(img_DIR, 'Paintings.csv')\n",
        "\n",
        "\n",
        "if BY_ARTIST:\n",
        "\n",
        "    # -- create mapping dictionnary for Artist (in alphabetic order)\n",
        "    artist_map_dic = {k: v for v, k in enumerate(sorted([ARTIST.name for ARTIST in ARTISTS ]))   }\n",
        "    print(artist_map_dic)\n",
        "    print(len(artist_map_dic))\n",
        "\n",
        "    # -- save DIR   \n",
        "    sample_dir = os.path.join(DIR,'generated','Wcgan')\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "    model_save_DIR = os.path.join(DIR,'Models')\n",
        "\n",
        "    all_painting_paths = []\n",
        "    all_labels  = []\n",
        "\n",
        "    for artist_path in artist_paths:\n",
        "        # -- create artist instance \n",
        "        artist = Artist(artist_path)\n",
        "        #print(f'--{artist.name}--')\n",
        "        artist_id =  artist_map_dic[artist.name]\n",
        "        # -- get list of painting paths\n",
        "        painting_paths = artist.painting_paths\n",
        "        # -- add to all all_painting_paths \n",
        "        all_painting_paths.extend(painting_paths)\n",
        "        all_labels.extend([artist_id] * artist.painting_nb)\n",
        "\n",
        "    print(len(all_painting_paths))\n",
        "    print(all_painting_paths[1000:1005])\n",
        "    print(len(all_labels))\n",
        "    print(all_labels[1000:1005])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 22 artists\n",
            "['/mydrive/GAN/Data/zdzislaw-beksinski', '/mydrive/GAN/Data/rembrandt', '/mydrive/GAN/Data/arnold-bocklin', '/mydrive/GAN/Data/gustav-klimt', '/mydrive/GAN/Data/katsushika-hokusai', '/mydrive/GAN/Data/pablo-picasso', '/mydrive/GAN/Data/vincent-van-gogh', '/mydrive/GAN/Data/ernst-ludwig-kirchner', '/mydrive/GAN/Data/theophile-steinlen', '/mydrive/GAN/Data/joseph-mallord-william-turner', '/mydrive/GAN/Data/sandro-botticelli', '/mydrive/GAN/Data/amedeo-modigliani', '/mydrive/GAN/Data/artemisia-gentileschi', '/mydrive/GAN/Data/piet-mondrian', '/mydrive/GAN/Data/edward-hopper', '/mydrive/GAN/Data/pierre-auguste-renoir', '/mydrive/GAN/Data/claude-monet', '/mydrive/GAN/Data/henri-rousseau', '/mydrive/GAN/Data/henri-matisse', '/mydrive/GAN/Data/david-burliuk', '/mydrive/GAN/Data/john-james-audubon', '/mydrive/GAN/Data/vassily-kandinsky']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOPxRyRdAx9F"
      },
      "source": [
        "### BY GENRE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pljOEegzAwlB",
        "outputId": "32748248-ad29-400f-d41c-badb09c74b82"
      },
      "source": [
        "if BY_GENRE:\n",
        "    filename ='Paintings.csv'\n",
        "    df = pd.read_csv(os.path.join(img_DIR,'Paintings.csv'), sep=';')\n",
        "    print(df.tail(5))\n",
        "\n",
        "    # -- convert Tags column to tuples\n",
        "    # df['Tags'] = df['Tags'].apply(eval)\n",
        "\n",
        "    # -- Genre\n",
        "    Genres = df['Genre'].unique()\n",
        "    print('Genres:', Genres)\n",
        "    print(f'There are {len(Genres)}')\n",
        "\n",
        "    print(df.groupby('Genre')['Filename'].count())\n",
        "\n",
        "    # -- Tags\n",
        "    # --- replace empty tags by NaN\n",
        "    df['Tags'] = df['Tags'].replace('()', np.nan)\n",
        "    all_Tags  = []\n",
        "\n",
        "    for t in  list(df['Tags'].dropna().values) :\n",
        "        t = t.replace(')', ',)') # because one elemnt tuple need to be in the form (item,)\n",
        "        t = eval(t)\n",
        "        if len(t) > 1:\n",
        "            for item in t:\n",
        "                all_Tags.append(item)\n",
        "        else: \n",
        "            try:\n",
        "                all_Tags.append(t[0])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    print(f'all_Tags {all_Tags[-5]}')\n",
        "    # -- count frequency of tags\n",
        "    print('')\n",
        "    print('Tag counting : ')\n",
        "    Tag_Counts = Counter(elem for elem in all_Tags)\n",
        "\n",
        "    print(Tag_Counts)\n",
        "\n",
        "    limit = 50\n",
        "    # -- select paintings by genre\n",
        "    painting_by_genre ={}\n",
        "    for genre in Genres:\n",
        "        painting_list = list(df[df['Genre']==genre]['Filename'])\n",
        "        if len(painting_list) > limit :\n",
        "            # -- add .jpg \n",
        "            painting_list = [painting for painting in painting_list]\n",
        "            painting_by_genre[genre] = painting_list\n",
        "\n",
        "\n",
        "    # -- create mapping dictionnary for Artist (in alphabetic order)\n",
        "    genre_map_dic = {k: v for v, k in enumerate(sorted([genre for genre in painting_by_genre.keys()]))   }\n",
        "    print('Genre map dic :', genre_map_dic)\n",
        "    print('Number of genre:', len(painting_by_genre))\n",
        "    # -- example of painting list for one giving genre \n",
        "    #print(painting_by_genre['figurative'])\n",
        "\n",
        "\n",
        "    # -- save DIR   \n",
        "    sample_dir = os.path.join(DIR,'generated','Wcgan','by_genre')\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "    model_save_DIR = os.path.join(DIR,'Models','by_genre')\n",
        "    os.makedirs(model_save_DIR , exist_ok=True)\n",
        "\n",
        "    log_dir = os.path.join(DIR,'logs','Wcgan','by_genre')\n",
        "\n",
        "    #all_painting_filenames = []\n",
        "    all_painting_paths = []\n",
        "    all_labels  = []\n",
        "\n",
        "    #print(df[df['Filename']=='spring-1907']['Artist'].values[0])\n",
        "\n",
        "    def get_painting_path(painting_filename):\n",
        "        artist = df[df['Filename']==painting_filename]['Artist'].values[0]\n",
        "        artist = str(artist).lower().replace(' ','-')\n",
        "        painting_path  = os.path.join(img_DIR, artist, painting_filename+'.jpg')\n",
        "        return painting_path \n",
        "\n",
        "    for genre in sorted(painting_by_genre.keys()):\n",
        "        print(genre)\n",
        "        genre_id =  genre_map_dic[genre]\n",
        "        print(genre_id)\n",
        "        # -- get list of painting paths\n",
        "        painting_filenames = painting_by_genre[genre]\n",
        "        painting_paths  = list(map(get_painting_path,painting_filenames))\n",
        "        # -- add to all all_painting_paths \n",
        "        all_painting_paths.extend(painting_paths)\n",
        "        all_labels.extend([genre_id] * len(painting_paths))\n",
        "        print('---')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               Filename  ...              Artist\n",
            "12396      plate-78-great-carolina-wren  ...  John James Audubon\n",
            "12397                plate-13-snow-bird  ...  John James Audubon\n",
            "12398   plate-19-louisiana-water-thrush  ...  John James Audubon\n",
            "12399  plate-127-rose-breasted-grosbeak  ...  John James Audubon\n",
            "12400   plate-130-yellow-winged-sparrow  ...  John James Audubon\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "Genres: ['allegorical painting' 'religious painting' 'portrait' nan\n",
            " 'mythological painting' 'landscape' 'symbolic painting'\n",
            " 'history painting' 'battle painting' 'sketch and study' 'self-portrait'\n",
            " 'literary painting' 'still life' 'sculpture' 'nude painting (nu)'\n",
            " 'animal painting' 'interior' 'poster' 'cityscape' 'illustration'\n",
            " 'advertisement' 'design' 'bird-and-flower painting' 'pastorale' 'vanitas'\n",
            " 'marina' 'cloudscape' 'flower painting' 'panorama' 'figurative'\n",
            " 'abstract' 'architecture' 'wildlife painting' 'quadratura']\n",
            "There are 34\n",
            "Genre\n",
            "abstract                     191\n",
            "advertisement                 10\n",
            "allegorical painting          83\n",
            "animal painting              139\n",
            "architecture                   1\n",
            "battle painting                9\n",
            "bird-and-flower painting      15\n",
            "cityscape                    709\n",
            "cloudscape                     3\n",
            "design                        21\n",
            "figurative                    26\n",
            "flower painting              415\n",
            "history painting              14\n",
            "illustration                 789\n",
            "interior                     104\n",
            "landscape                   2079\n",
            "literary painting             20\n",
            "marina                       147\n",
            "mythological painting        134\n",
            "nude painting (nu)           584\n",
            "panorama                       3\n",
            "pastorale                      1\n",
            "portrait                    2045\n",
            "poster                        49\n",
            "quadratura                     1\n",
            "religious painting           302\n",
            "sculpture                     19\n",
            "self-portrait                185\n",
            "sketch and study            1404\n",
            "still life                   518\n",
            "symbolic painting            654\n",
            "vanitas                        6\n",
            "wildlife painting             22\n",
            "Name: Filename, dtype: int64\n",
            "all_Tags Plant\n",
            "\n",
            "Tag counting : \n",
            "Counter({'Sketch': 1578, 'Tree': 1395, 'Plant': 912, 'Lady': 908, 'Sky': 908, 'female-portraits': 805, 'allegories-and-symbols': 759, 'male-portraits': 566, 'Natural landscape': 538, 'Figure drawing': 534, 'Flower': 487, 'female-nude': 445, 'Head': 428, 'Chin': 416, 'Water': 411, 'Botany': 406, 'Text': 402, 'Still life photography': 389, 'Cheek': 365, 'forests-and-trees': 328, 'handwork': 315, 'Face': 310, 'countryside': 304, 'Human': 297, 'houses-and-buildings': 295, 'Nose': 294, 'Woody plant': 287, 'flowers-and-plants': 275, 'animals': 258, 'Bank': 253, 'Line': 251, 'Vehicle': 228, 'Mythology': 227, 'Forehead': 223, 'Nature': 211, 'fields-and-plains': 210, 'famous-people': 209, 'walking': 204, 'Gentleman': 202, 'gardens-and-parks': 196, 'Organism': 186, 'boats-and-ships': 182, 'Natural environment': 179, 'mountains': 168, 'Boat': 167, 'Waterway': 165, 'Sitting': 157, 'Rock': 156, 'streets-and-squares': 151, 'couples': 149, 'Leaf': 145, 'Arm': 136, 'Facial hair': 133, 'Branch': 130, 'Standing': 129, 'Sea': 129, 'seas-and-oceans': 126, 'Christianity': 125, 'cottages-and-farmhouses': 123, 'Meadow': 121, 'Atmosphere': 118, 'characters-and-emotions': 117, 'Textile': 117, 'Rural area': 116, 'House': 116, 'cliffs-and-rocks': 115, 'Cliff': 112, 'Reflection': 108, 'dishware-and-cutlery': 107, 'Bouquet': 107, 'spring': 106, 'rivers-and-waterfalls': 101, 'Font': 99, 'Hair': 98, 'Grass family': 98, 'Normandy': 96, 'Atmospheric phenomenon': 95, 'roads-and-vehicles': 92, 'furniture-and-decoration': 91, 'Watercraft': 90, 'Coast': 90, 'Bird': 88, 'Bayou': 87, 'Forest': 84, 'River': 83, 'Male': 83, 'horses': 81, 'male-nude': 80, 'Grass': 80, 'domestic-settings': 76, 'musical-instruments': 74, 'Beard': 74, 'Woodland': 74, 'Brown': 73, 'Orange': 73, 'autumn': 72, 'Hairstyle': 71, 'Mountain': 70, 'Cut flowers': 70, 'birds': 69, 'Building': 69, 'Picture frame': 68, 'Terrain': 68, 'Flowering plant': 68, 'folk-architecture': 68, 'Cloud': 67, 'Garden roses': 67, 'Greek-and-Roman-Mythology': 66, 'monuments-and-statues': 66, 'mealtimes': 66, 'Stock photography': 65, 'arts-and-crafts': 65, 'fruits-and-vegetables': 64, 'Vegetation': 63, 'Room': 63, 'winter': 63, 'Eyebrow': 62, 'mother-and-child': 62, 'Photograph': 61, 'Pattern': 60, 'Fictional character': 59, 'Wildflower': 59, 'Flowerpot': 58, 'mills-and-windmills': 57, 'Eye': 57, 'Holy places': 57, 'horsemen': 56, 'Leg': 56, 'Jaw': 56, 'Joint': 55, 'Pond': 55, 'water lily': 54, 'morning': 52, 'leisure-and-sleep': 52, 'parts-of-human-body': 51, 'Fruit': 50, 'Grassland': 50, 'Northern hardwood forest': 50, 'twilight-and-night': 49, 'children portraits': 48, 'Graphic design': 48, 'Child': 48, 'Neck': 48, 'Cat': 48, 'Shore': 48, 'skeletons-and-skulls': 47, 'Paris': 47, 'Trunk': 47, 'Virgin-and-Child': 47, 'monochrome': 46, 'costume design': 46, 'Human body': 45, 'actors-and-performances': 45, 'Vintage advertisement': 45, 'fashion': 44, 'Headgear': 44, 'Bridge': 44, 'children': 43, 'sunrise-and-sunset': 43, 'Fashion illustration': 43, 'Formation': 42, 'Felidae': 42, 'gates-and-towers': 42, 'Sailboat': 42, 'Vincent-Van-Gogh': 42, 'Headland': 42, 'castles-and-fortresses': 41, 'group-portraits': 41, 'Arch': 40, 'fictional-characters': 40, 'Rose': 40, 'Watercourse': 39, 'reading-and-writing': 38, 'Hand': 38, 'doors-and-windows': 38, 'Food': 38, 'Long hair': 36, 'Pink': 36, 'Sail': 36, 'harvesting': 36, 'Geological phenomenon': 34, 'Lip': 34, 'Geology': 34, 'Vase': 34, 'Field': 34, 'food-and-beverages': 33, 'Chest': 33, 'Prophet': 33, 'Retro style': 33, 'factories-and-plants': 33, 'Ocean': 32, 'Small to medium-sized cats': 32, 'History': 32, 'flying': 31, 'taverns-and-inns': 31, 'Road': 31, 'bulls': 31, 'Sailing': 31, 'Furniture': 31, 'Biome': 31, 'Footwear': 30, 'Brittany': 30, 'Jesus-Christ': 29, 'saints-and-apostles': 29, 'Turquoise': 29, 'cows': 29, 'Religious item': 29, 'Handwriting': 29, 'games-and-sport': 28, 'City': 28, 'Town': 28, 'cemeteries-and-tombs': 27, 'Hill': 27, 'Home': 27, 'Dress': 26, 'Ruins': 26, 'Arles': 26, 'instruments-and-mechanisms': 26, 'Jeanne-Hebuterne': 26, 'Horse': 25, 'islands-and-bays': 25, 'People in nature': 25, 'Marie-Thérèse Walter': 25, 'families': 25, 'Interaction': 25, 'Rectangle': 25, 'Victorian fashion': 25, 'Sailing ship': 25, 'Galiot': 25, 'Mountainous landforms': 25, 'Windmill': 25, 'Lavender': 25, 'Floral design': 24, 'angels-and-archangels': 23, 'Beauty': 23, 'Wilderness': 23, 'lakes-and-ponds': 23, 'cafes-and-restaurants': 23, 'Pablo-Picasso': 23, 'Carnivore': 23, 'manors-and-plantations': 23, 'jungles-and-tropics': 23, 'Pasture': 22, 'devils-and-demons': 22, 'Canidae': 22, 'Medieval architecture': 22, 'Twig': 22, 'Vegetarian food': 22, 'Old-Testament': 21, 'Snow': 21, 'Iris': 21, 'Prairie': 21, 'summer': 20, 'Outerwear': 20, 'beasts-and-dragons': 20, 'Infrastructure': 20, 'lamps-and-candles': 20, 'Minotaur': 20, 'books-and-letters': 20, 'People': 20, 'Cross': 20, 'Calm': 20, 'Beige': 20, 'fireplaces': 20, 'Canoe birch': 20, 'Harbor': 20, 'Plant community': 19, 'sunlight': 19, 'family-portraits': 19, 'Black hair': 19, 'cats': 19, 'fish': 19, 'Violet': 19, 'Mount-Fuji': 19, 'Sunflower': 19, 'ruins-and-columns': 18, 'conversations': 18, 'designs-and-sketches': 18, 'Symbol': 18, 'Wave': 18, 'Paper product': 18, 'Rose family': 18, 'Shoulder': 17, 'Stone carving': 17, 'Moustache': 17, 'Ecoregion': 17, 'Canal': 17, 'Wind wave': 17, 'East indiaman': 17, 'Whiskers': 17, 'Birch': 17, 'Marusia-Burliuk': 17, 'Belle-Île': 17, 'night': 16, 'Fiction': 16, 'Bovine': 16, 'Statue': 16, 'Vintage clothing': 16, 'Reading': 16, 'Galleon': 16, 'moles-and-embankments': 16, 'Old-growth forest': 16, 'Floristry': 16, 'Wetland': 16, 'Interior design': 16, 'nymphs-and-satyrs': 15, 'military-and-soldiers': 15, 'women-and-mirrors': 15, 'celebrations-and-festivals': 15, 'markets-and-shops': 15, 'Coquelicot': 15, 'Chair': 15, 'Tints and shades': 15, 'Dog': 15, 'Water transportation': 15, 'Village': 15, 'Hat': 15, 'Coastal and oceanic landforms': 15, 'Klippe': 15, 'Clothing': 14, 'Snapshot': 14, 'fishing': 14, 'clothing-and-textile': 14, 'Serveware': 14, 'troubles-and-disasters': 14, 'Musical instrument': 14, 'Mast': 14, 'rain-and-fog': 14, 'railway': 14, 'Winter squash': 14, 'Jungle': 14, 'Evening': 13, 'Harlequin': 13, 'Seine': 13, 'Organ': 13, 'Classical sculpture': 13, 'Human settlement': 13, 'Musician': 13, 'Darkness': 13, 'floor-and-ceiling': 13, 'Clipper': 13, 'Chrysanths': 13, 'Watercraft rowing': 13, 'Nature reserve': 13, 'Marsh': 13, 'hunting-and-racing': 12, 'caves-and-volcanoes': 12, 'birth-and-death': 12, 'bathing-and-swimming': 12, 'goats': 12, 'Palm tree': 12, 'words': 12, 'Beak': 12, 'Wildlife': 12, 'Crucifix': 12, 'Skull': 12, 'Fluyt': 12, 'Ship of the line': 12, 'Table': 12, 'Manga': 12, 'margins-and-wastelands': 12, 'Dirt road': 12, 'Grove': 12, 'Flower Arranging': 12, 'Vegetable': 12, 'Berlin': 12, 'double-portraits': 12, 'Limousin': 12, 'Creuse': 12, 'Aquatic plant': 12, 'Beatrice-Hastings': 12, 'battles-and-wars': 11, 'Relief': 11, 'Monochrome photography': 11, 'Working animal': 11, 'Skin': 11, 'Human anatomy': 11, 'Tail': 11, 'Muscle': 11, 'sun-and-moon': 11, 'Highland': 11, 'Horse and buggy': 11, 'Bird of prey': 11, 'Swamp': 11, 'Galway hooker': 11, 'Rome': 10, 'villas-and-residences': 10, 'knights-and-warriors': 10, 'Date palm': 10, 'masks-and-fans': 10, 'Umbrella': 10, 'Elephant': 10, 'Majorelle blue': 10, 'Human leg': 10, 'spirits-and-ghosts': 10, 'Viaduct': 10, 'gods-and-goddesses': 10, 'Adaptation': 10, 'Glass bottle': 10, 'Wagon': 10, 'Cuisine': 10, 'deserts-and-steppes': 10, 'Bird nest': 10, 'Pan/Satyr': 9, 'lonely figures': 9, 'Arecales': 9, 'fountains-and-pools': 9, 'studios-and-workshops': 9, 'hens': 9, 'Galliformes': 9, 'newspapers': 9, 'Ox': 9, 'Jug': 9, 'Black cat': 9, 'bedrooms': 9, 'Crucifixion': 9, 'Bottle': 9, 'Tower': 9, 'Knee': 9, 'arcades-and-colonnades': 9, 'Horizon': 9, 'First-rate': 9, 'Flagship': 9, 'Tide': 9, 'Vertebrate': 9, 'Pheasant': 9, 'Comics': 9, 'Comic book': 9, 'Book cover': 9, 'Roof': 9, 'Coachman': 9, 'Writing': 9, 'hospitals-and-pharmacies': 9, 'Floribunda': 9, 'Temperate broadleaf and mixed forest': 9, 'Dish': 9, 'Street': 9, 'Monarch': 9, 'Fecamp': 9, 'String instrument': 9, 'Murnau': 9, 'Virgin-Mary': 8, 'Fun': 8, 'games-and-toys': 8, 'artists-and-models': 8, 'Barechested': 8, 'pictures-and-drafts': 8, 'Elephants and Mammoths': 8, 'Las Meninas': 8, 'monkeys': 8, 'Carving': 8, 'gypsies': 8, 'Apple': 8, 'stars-and-planets': 8, 'Freezing': 8, 'Venice': 8, 'Gondola': 8, 'Recreation': 8, 'Facade': 8, 'Hut': 8, 'Transport': 8, 'storm-and-tempest': 8, 'Neighbourhood': 8, 'Farmhouse': 8, 'Mill': 8, 'Turban': 8, 'Carriage': 8, 'Shrub': 8, 'Dresden': 8, 'Holy-Family': 8, 'lions': 8, 'St. John the Baptist': 8, 'Body of water': 8, 'prayers': 7, 'Centaurs': 7, 'Aphrodite/Venus': 7, 'Flight-into-Egypt': 7, 'religious-items': 7, 'dogs': 7, 'posters-and-advertisements': 7, 'Manuel de Falla \"Tricorne\"': 7, 'Bronze sculpture': 7, 'Bull': 7, 'Terrestrial animal': 7, 'pigeons': 7, 'Circle': 7, 'Figurine': 7, 'Snout': 7, 'Ancient history': 7, 'Space': 7, 'Landmark': 7, 'fires-and-floods': 7, 'Alps': 7, 'Spire': 7, 'Arch bridge': 7, 'Water resources': 7, 'Caravel': 7, 'Hague': 7, 'insects': 7, 'Dante-Alighieri-\"The-Divine-Comedy\"': 7, 'pilgrims': 7, 'Lighthouse': 7, 'Garden': 7, 'Tall ship': 7, 'Leopold-Zborowski': 7, 'Holly': 7, 'fauns': 6, 'self-portrait': 6, 'chicken': 6, 'rooster': 6, 'Outcrop': 6, 'Cow-goat family': 6, 'Barcelona': 6, 'hygiene-and-cosmetics': 6, 'sheep': 6, 'Plate': 6, 'donkeys': 6, 'Coloring book': 6, 'cigarettes-and-pipes': 6, 'Crowd': 6, 'Bone': 6, 'Wing': 6, 'Flesh': 6, 'Church': 6, 'Chapel': 6, 'Frigate': 6, 'Dog breed': 6, 'Dance': 6, 'Tabby cat': 6, 'Turkey': 6, 'Blossom': 6, 'Boating': 6, 'Nuenen': 6, 'Lazarus': 6, 'Cottage': 6, 'Onion': 6, 'valleys-and-hollows': 6, 'Mother': 6, 'Hay': 6, 'Houseplant': 6, 'theatres': 6, 'Gown': 6, 'Japan': 6, 'Moscow': 6, 'Fish pond': 6, 'Plucked string instruments': 6, 'muses': 5, 'Fur': 5, 'Odysseus/Ulysses': 5, 'Beach': 5, 'Olga Khokhlova': 5, 'scene-design': 5, 'Pierrot': 5, 'Shoe': 5, 'Window': 5, 'Livestock': 5, 'Bridle': 5, 'Rein': 5, 'Ear': 5, 'Wrinkle': 5, 'Personal protective equipment': 5, 'Mouth': 5, 'aircrafts': 5, 'Fashion design': 5, 'Ship': 5, 'walls-and-staircases': 5, 'Arcade': 5, 'Mammal': 5, 'Novel': 5, 'Map': 5, 'serpents-and-snakes': 5, 'Foot': 5, 'Uniform': 5, 'Pianist': 5, 'Gourd': 5, 'Horse harness': 5, 'Steeple': 5, 'Finger': 5, 'Barn': 5, 'Owl': 5, 'Crop': 5, 'Insect': 5, 'Farm': 5, 'Mode of transport': 5, 'Chariot': 5, 'Switzerland': 5, 'Water bird': 5, 'St.-Augustine': 5, 'Annunciation': 5, 'Boccaccio-\"The-Decameron\"': 5, 'New-York': 5, 'Property': 5, 'Mountain range': 5, 'Honfleur': 5, 'Loch': 5, 'Trouville': 5, 'fragrant white water lily': 5, 'Colorfulness': 5, 'rousseau': 5, 'Falcon': 5, 'Coraciiformes': 5, 'Hummingbird': 5, 'Shrubland': 4, \"Devil's bridge\": 4, 'Cupid-and-Psyche': 4, 'Fur clothing': 4, 'swamps': 4, 'shepherds': 4, 'priests-and-sacraments': 4, 'Elaeis': 4, 'seashells': 4, 'crimes': 4, 'Tradition': 4, 'Lion': 4, 'Meal': 4, 'Sebastia Junyer-Vidal': 4, 'Newsprint': 4, 'punishments-and-tortures': 4, 'Car': 4, 'prisons-and-prisoners': 4, 'Petal': 4, 'clocks-and-hourglasses': 4, 'Schooner': 4, 'Galley': 4, 'snow-and-blizzard': 4, 'Siamese': 4, 'Indian elephant': 4, 'Advertising': 4, 'Tulip': 4, 'Geisha': 4, 'Wild turkey': 4, 'sparrows': 4, 'Stratovolcano': 4, 'Tourism': 4, 'Residential area': 4, 'Terrestrial plant': 4, 'Almshouse': 4, 'Shipwreck': 4, 'Frost': 4, 'lanterns': 4, 'Tropical and subtropical coniferous forests': 4, 'Games': 4, 'parables-of-Jesus': 4, 'Pedicel': 4, 'Natural foods': 4, 'yards': 4, 'Parallel': 4, 'Humpback bridge': 4, 'Shadow': 4, 'ducks': 4, 'Resurrection-of-Lazarus': 4, 'Abraham': 4, 'David': 4, 'Adam': 4, 'Lucretia': 4, 'Back': 4, 'Wedding dress': 4, 'American aspen': 4, 'Nativity scene': 4, 'Moses': 4, 'Vladimir-Mayakovsky': 4, 'Fell': 4, 'Fishing vessel': 4, 'Stack': 4, 'Boats and boating--Equipment and supplies': 4, 'Rust': 4, 'Blizzard': 4, 'Stream': 4, 'Pomegranate': 4, 'tigers': 4, 'Cup': 4, 'Phasianidae': 4, 'Kobza': 4, 'Curtain': 4, 'Russia': 4, 'Kochel': 4, 'rituals-and-traditions': 3, 'ceremonies': 3, 'historical-events': 3, 'naval-battles': 3, 'murder-and-suicide': 3, 'Death': 3, 'Homer': 3, 'Nessus': 3, 'solitude': 3, 'Sunset': 3, 'Fowl': 3, 'Comb': 3, 'Rape of the Sabine Women': 3, 'Horn': 3, 'kitchens': 3, 'Dancer': 3, 'Tile': 3, 'dining rooms': 3, 'Bison': 3, 'Ceramic': 3, 'Dishware': 3, 'rooftops': 3, 'Igor Stravinsky \"Pulcinella\"': 3, 'Burro': 3, 'Azure': 3, 'arthropod': 3, 'owls': 3, 'Pear': 3, 'Facial expression': 3, 'African elephant': 3, 'harems': 3, 'Guitarist': 3, 'palaces-and-mausoleums': 3, \"hunter's-and-fisher's-trophies\": 3, 'Wine bottle': 3, 'Headstone': 3, 'Ice': 3, 'Historic site': 3, 'Light': 3, 'Monolith': 3, 'Eyewear': 3, 'Badlands': 3, 'government buildings': 3, 'London': 3, 'Castle': 3, 'Classical architecture': 3, 'rainbows': 3, 'Storm': 3, 'Savanna': 3, 'Galeas': 3, 'deer': 3, 'Tango': 3, 'Sporting Group': 3, 'World': 3, 'Hand fan': 3, 'butterflies': 3, 'Military camouflage': 3, 'Pole': 3, 'Grape': 3, 'Shack': 3, 'Railroad car': 3, 'Lumberjack': 3, 'Document': 3, 'Rosa × centifolia': 3, 'oxen': 3, 'Saint-Rémy': 3, 'halls-and-corridors': 3, 'Rhone': 3, 'Team': 3, 'Antwerp': 3, 'Auvers-sur-Oise': 3, 'moths': 3, 'Harvest': 3, 'Coat': 3, 'Conifer': 3, 'France': 3, 'Prickly rose': 3, 'Barn owl': 3, 'Motor vehicle': 3, 'washing-and-laundry': 3, 'Entombment-of-Christ': 3, 'philosophers': 3, 'St.-Peter': 3, 'Prodigal-Son': 3, 'Isaac': 3, 'Formal wear': 3, 'Elder': 3, 'Fen': 3, 'Classical music': 3, 'Inferno': 3, 'Nastagio-Degli-Onesti': 3, 'St.-Zenobius': 3, 'heroes': 3, 'cossacks': 3, 'Aster': 3, 'Natural arch': 3, 'Ridge': 3, 'Botanical garden': 3, 'Couch': 3, 'Cove': 3, 'Barquentine': 3, 'Horse tack': 3, 'Winter storm': 3, 'Pumpkin': 3, 'Lane': 3, 'Baby': 3, 'Symmetry': 3, 'Rabbit': 3, 'Rabbits and Hares': 3, 'Domestic rabbit': 3, 'Hare': 3, 'Cello': 3, 'Diego-Rivera': 3, 'Moise-Kisling': 3, 'Chaime-Soutine': 3, 'Mcintosh': 3, 'Music': 3, 'Beacon': 3, 'Stairs': 3, 'Jay': 3, 'Peregrine falcon': 3, 'Vulture': 3, 'Hawk': 3, 'European Swallow': 3, 'Woodpecker': 3, 'Sirens': 2, 'Artemis/Diana': 2, 'Cleopatra': 2, 'Pietà': 2, 'Heracles/Hercules': 2, 'Angelica': 2, 'Bathing': 2, 'cherubs-and-seraphs': 2, 'Headpiece': 2, 'Plague-of-Pestilence': 2, 'St.-Anthony': 2, 'Danae': 2, 'Poultry': 2, 'Francisco Franco': 2, 'Spanish Civil War': 2, 'Jacinto Salvado': 2, 'Bedrock': 2, 'Antler': 2, 'Horse trainer': 2, 'disease-and-treatment': 2, 'Zebu': 2, 'Salome': 2, 'Platter': 2, 'Tableware': 2, 'Dora Maar': 2, 'Giraffe': 2, 'Peach': 2, 'Glasses': 2, 'mules': 2, 'Animal sports': 2, 'ravens': 2, 'Paloma Picasso': 2, 'Kneeling': 2, 'Monument': 2, 'Jupiter/Zeus': 2, 'Social group': 2, 'Don-Quixote': 2, 'Sancho-Panza': 2, 'Tunnel': 2, 'pyramids-and-ziggurats': 2, 'Automotive design': 2, 'Mask': 2, 'Daytime': 2, 'Skyline': 2, 'Heat': 2, 'Smoke': 2, 'Flautist': 2, 'Château': 2, 'Estate': 2, 'Vault': 2, 'Great-Flood': 2, 'Deluge': 2, 'Crypt': 2, 'Triumphal arch': 2, 'Herd': 2, 'Rainbow': 2, 'Wild cat': 2, 'Ocicat': 2, 'European shorthair': 2, 'Ancient dog breeds': 2, 'Vintage car': 2, 'Event': 2, 'Plain': 2, 'Clàrsach': 2, 'Guillotine': 2, 'Camel': 2, 'Arabian camel': 2, 'Kitten': 2, 'Album cover': 2, 'Domestic short-haired cat': 2, 'Book': 2, 'Sleep': 2, 'Soldier': 2, 'Hug': 2, 'Cumulus': 2, 'chariots': 2, 'travellers': 2, 'Katsushika Hokusai': 2, 'swallows': 2, 'Tortoise': 2, 'Turtle': 2, 'Reptile': 2, 'Flag': 2, 'Urban design': 2, 'Grizzly bear': 2, 'Volcanic landform': 2, 'falcons': 2, 'Matsuo Bashō': 2, 'Bear': 2, 'Volcano': 2, 'fightings': 2, 'Carrack': 2, 'kingfishers': 2, 'Thatching': 2, 'Train': 2, 'Locomotive': 2, 'Rolling stock': 2, 'Miracles': 2, 'Raising-of-Lazarus': 2, 'beetles': 2, 'Goat-antelope': 2, 'Shepherd': 2, 'Goatherd': 2, 'Herder': 2, 'Primate': 2, 'spinning': 2, 'Red onion': 2, 'waiting': 2, 'Butterfly': 2, 'Agriculture': 2, 'Letter': 2, 'ballrooms': 2, 'Cowboy hat': 2, 'Gesture': 2, 'Ingredient': 2, 'Good-Samaritan': 2, 'rabbits': 2, 'Cobblestone': 2, 'Mane': 2, 'Sorrel': 2, 'crabs': 2, 'Invertebrate': 2, 'White pine': 2, 'red pine': 2, 'swifts': 2, 'Plough': 2, 'Dining room': 2, 'Suit': 2, 'Pine family': 2, 'Green algae': 2, 'Algae': 2, 'Restaurant': 2, 'Iris family': 2, 'scientists': 2, 'St.-Paul': 2, 'friars-and-monks': 2, 'Purification-of-temple': 2, 'Adoration-of-the-Shepherds': 2, 'Eve': 2, 'Conquistador': 2, 'Big cats': 2, 'Christmas': 2, 'Theatre': 2, 'Schubert': 2, 'Bridal accessory': 2, 'Bridal clothing': 2, 'Bride': 2, 'hope': 2, 'time-and-age': 2, 'Paradise': 2, 'Ahtena': 2, 'Mars': 2, 'Middle ages': 2, 'Holofernes': 2, 'jewish-mythology': 2, 'Judith': 2, 'skyscrapers': 2, 'Nicholas-Roerich': 2, 'Wassily-Kamensky': 2, 'Anna-Maria-Island': 2, 'Ogasawara': 2, 'hydrangea': 2, 'Gladiolus': 2, 'Lotus family': 2, 'Canoe': 2, 'Tablecloth': 2, 'Concrete bridge': 2, 'Beam bridge': 2, 'Public space': 2, 'Town square': 2, 'Plaza': 2, 'Trail': 2, 'Steam engine': 2, 'Steam': 2, 'Skipjack': 2, 'Produce': 2, 'Full-rigged ship': 2, 'Wisteria': 2, 'Cucurbita': 2, 'Promontory': 2, 'Lake': 2, 'corn poppy': 2, 'oriental poppy': 2, 'Fish products': 2, 'English lavender': 2, 'Flamenco': 2, 'Piet-Mondrian': 2, 'Door': 2, 'jaguar': 2, 'Sport venue': 2, 'Eiffel-tower': 2, 'Teapot': 2, 'Cellist': 2, 'Violin family': 2, 'Paul-Guillaume': 2, 'Anna-Akhmatova': 2, 'Citrus': 2, 'Drinkware': 2, 'Yellow onion': 2, 'Shallot': 2, 'Afterglow': 2, 'Calabaza': 2, 'Toddler': 2, 'Wine glass': 2, 'Ballet dancer': 2, 'Veena': 2, 'Brown hair': 2, 'Romance': 2, 'Painter': 2, 'Picnic': 2, 'Lute': 2, 'Mandolin': 2, 'Snowboard': 2, 'Egg': 2, 'Corsica': 2, 'Anthurium': 2, 'Monhegan': 2, 'Sloop': 2, 'Dinghy sailing': 2, 'Column': 2, 'Okhtyrka': 2, 'Hornbill': 2, 'Ikebana': 2, 'Blue jay': 2, 'Blackbird': 2, 'Crow': 2, 'Raven': 2, 'Plane': 2, 'Parrot': 2, 'Eagle': 2, 'Accipitriformes': 2, 'Pileated woodpecker': 2, 'Piciformes': 2, 'Mountain Cottontail': 2, \"Audubon's Cottontail\": 2, 'Lower Keys Marsh Rabbit': 2, 'Black tailed jackrabbit': 2, 'wood rabbit': 2, 'Chaparral': 1, 'pirates': 1, 'Medusa': 1, 'Mermaid': 1, 'Fiddle': 1, 'Skeleton': 1, 'Syrinx': 1, \"will-o'-the-wisp\": 1, 'bagpipers': 1, 'swans': 1, 'mermaids': 1, 'Drink': 1, 'Dinard': 1, 'Sergei Diaghilev': 1, 'Alfred Seligsberg': 1, 'Adonis': 1, 'Acoustic guitar': 1, 'Nusch éluard': 1, 'Black rhinoceros': 1, 'Triceratops': 1, 'Rhinoceros': 1, 'Antelope': 1, 'Icarus': 1, 'Rafael Alberti \"The eight names of Picasso\"': 1, 'Erik Satie \"Parade\"': 1, 'Pegasus': 1, 'Lunch': 1, 'Paul éluard': 1, 'Pierre-Auguste Renoir': 1, 'Water buffalo': 1, 'Igor-Stravinsky': 1, 'Honoré de Balzac \"The Unknown Masterpiece\"': 1, 'Silenus': 1, 'Ambroise Vollard': 1, 'Alfred Sisley': 1, 'Valencia': 1, 'Jaime Sabartes': 1, 'Amphibian': 1, 'Frog': 1, 'doves': 1, 'covers': 1, 'Western Tanager': 1, 'Finch': 1, 'urchins': 1, 'Niko-Pirosmani': 1, 'Jacqueline Roque': 1, 'Chalice': 1, 'Antiope': 1, 'Erik Satie': 1, 'Sebastià Junyent Sans': 1, 'Gertrude Stein': 1, 'Giraffidae': 1, 'Juan-les-Pins': 1, 'Daniel-Henry Kahnweiler': 1, 'Colombina': 1, 'Stomach': 1, 'silhouette': 1, 'Armour': 1, 'musketeers': 1, 'Henri II': 1, 'Nusch Éluard': 1, 'Hatter': 1, 'Puffin': 1, 'Pulcinella': 1, 'Grave': 1, 'Cemetery': 1, 'Celestial event': 1, 'moon': 1, 'Digital compositing': 1, 'Mist': 1, 'Gas mask': 1, 'Sculptor': 1, 'Megalith': 1, 'Tooth': 1, 'Zdislav-Beksinski': 1, 'Electricity': 1, 'Close-up': 1, 'Skyscraper': 1, 'Manor house': 1, 'Stately home': 1, 'Moonlight': 1, 'Canyon': 1, 'Fault': 1, 'Ten-Plagues': 1, 'Abbey': 1, 'Naples': 1, 'Sunrise': 1, 'Lake-Geneva': 1, 'Fisherman': 1, 'sibyls': 1, 'Aeneas': 1, 'Hermes/Mercury': 1, 'Hunting dog': 1, 'Montenegrin mountain hound': 1, 'Peafowl': 1, 'Seahorse': 1, 'Movie': 1, 'Newspaper': 1, 'Notebook': 1, 'Camelid': 1, 'Rodeo': 1, 'Product': 1, 'Norwegian forest cat': 1, 'Birman': 1, 'Puma': 1, 'Marsupial': 1, 'Squirrel': 1, 'Tonkinese': 1, 'Toyger': 1, 'California spangled': 1, 'Asian': 1, 'Nap': 1, 'Antique': 1, 'Tanuki': 1, 'Hotei': 1, 'Galápagos tortoise': 1, 'Olive ridley sea turtle': 1, 'Green sea turtle': 1, 'Sea turtle': 1, 'Fishing net': 1, 'Fashion accessory': 1, 'witches': 1, 'shamans-and-sorcerers': 1, 'Cherry blossom': 1, 'Raigo Ajari Kaisoden': 1, 'Pyramid': 1, 'housekeeping': 1, 'grasshoppers': 1, 'bulrush': 1, 'carps': 1, 'Tire': 1, 'Automotive tire': 1, 'octopuses': 1, 'Octopus': 1, 'Rat': 1, 'Muridae': 1, 'Brown bear': 1, 'Slope': 1, 'Shimada': 1, 'Bat': 1, 'Crane': 1, 'Kappa': 1, 'Longship': 1, 'Viking ships': 1, 'cranes': 1, 'Shield volcano': 1, 'banks-and-money': 1, 'Amusement park': 1, 'Decorative fan': 1, 'Vitis': 1, 'Manila galleon': 1, 'Trireme': 1, 'grosbeaks': 1, 'mice': 1, 'Sun Wukong': 1, 'Serpent': 1, 'Snake': 1, 'Scaled reptile': 1, 'Colubridae': 1, 'Ankle': 1, 'Track': 1, 'Broom': 1, 'Thoroughfare': 1, 'Bible': 1, 'Herding': 1, 'Calf': 1, 'common peony': 1, 'Crew': 1, 'Gothic architecture': 1, 'Street light': 1, 'Light fixture': 1, 'Lighting': 1, 'Lamp': 1, 'Boardwalk': 1, 'Notre-Dame-de-Paris': 1, 'cicadas': 1, 'Drosophila melanogaster': 1, 'house fly': 1, 'Cicada': 1, 'Pest': 1, 'Bee': 1, 'Membrane-winged insect': 1, 'Fly': 1, 'Honeybee': 1, 'Forget-me-not': 1, 'prostitutas': 1, 'brothels': 1, 'Sled dog': 1, 'larks': 1, 'Freshwater marsh': 1, 'Phragmites': 1, 'Log cabin': 1, 'rats': 1, 'Rodent': 1, 'Saint-Rémy-de-Provence': 1, 'Spruce-fir forest': 1, 'bats': 1, 'Recreation room': 1, 'parrots': 1, 'Paddy field': 1, 'Trabaccolo': 1, 'Steamboat': 1, 'Mare': 1, 'Crab': 1, 'Decapoda': 1, 'King crab': 1, 'Crustacean': 1, 'Dungeness crab': 1, 'Paul-Gauguin': 1, 'Paw': 1, 'Barefoot': 1, 'Root vegetable': 1, 'Potato': 1, 'Machine tool': 1, 'Military officer': 1, 'Beetle': 1, 'shortstraw pine': 1, 'lodgepole pine': 1, 'Evergreen': 1, 'Jack pine': 1, 'Washing': 1, 'Camouflage': 1, 'Moths and butterflies': 1, 'Moth': 1, 'Pollinator': 1, 'Loom': 1, 'Tool': 1, 'Battle': 1, 'Strategy video game': 1, 'Floor': 1, 'Hardwood': 1, 'Flooring': 1, 'Barley': 1, 'Rye': 1, 'Overcoat': 1, 'Sleeve': 1, 'Cash crop': 1, 'Liqueur': 1, 'Military uniform': 1, 'Ciociaria': 1, 'Brickwork': 1, 'Brick': 1, 'Bigtree': 1, 'Scheveningen': 1, 'grape hyacinth': 1, 'Chaise': 1, 'Chaponval': 1, 'pastoral-scenes': 1, 'Pontius-Pilate': 1, 'Ruth': 1, 'Boaz': 1, 'Ironclad warship': 1, 'Warship': 1, 'Armored cruiser': 1, 'Drum': 1, 'Canopy bed': 1, 'Scene': 1, 'Jacob-Wrestling-with-the-Angel': 1, 'Hera/Juno': 1, 'Aristotle': 1, 'pigs': 1, 'St.-Stephen': 1, 'Drinking': 1, 'Alcoholic beverage': 1, 'beggar': 1, 'Esther': 1, 'Ahasuerus': 1, 'Haman': 1, 'St.-Matthew': 1, 'Binding-of-Isaac': 1, 'Bansuri': 1, 'Flute': 1, 'Bird-of-paradise': 1, 'New-Testament': 1, 'Supernatural creature': 1, 'prophets': 1, 'elephants': 1, 'Cupid': 1, 'Saul': 1, 'Musical instrument accessory': 1, 'Concert hall': 1, 'Opera house': 1, 'heater': 1, 'Stage': 1, 'Orchestra pit': 1, 'Auditorium': 1, 'Lace': 1, 'Sappho': 1, 'expectation': 1, 'William-Shakespeare-\"Romeo-and-Juliet\"': 1, 'Kiss': 1, 'Stable': 1, 'Duck': 1, 'tragedy': 1, 'Haute couture': 1, 'justice-and-court': 1, 'medicine': 1, 'Athena/Minerva': 1, 'Garden cosmos': 1, 'Rug': 1, 'St.-Ignatius': 1, 'The-Fotitude': 1, 'The-Agony': 1, 'cavalry': 1, 'Virginia': 1, 'Roman-Republic': 1, 'St.-John-of-Pathmos': 1, 'Seven-Liberal-Arts': 1, 'Purgatory': 1, 'Abundance': 1, 'Flagellation-of-Christ': 1, 'St.-Zinobius': 1, 'Dante': 1, 'St.-Sebastian': 1, 'Lucian-\"On-Calumny\"': 1, 'Apelles': 1, 'Hell': 1, 'Temptation of Christ': 1, 'Mordecai': 1, 'Transfiguration': 1, 'Giuliano-de-Medici': 1, 'Scallop': 1, 'Sixtus-II': 1, 'St.-Eligius': 1, 'police/militia': 1, \"Noah's-Ark\": 1, 'Naval architecture': 1, 'David-Burliuk': 1, 'Dnieper': 1, 'protest-actions': 1, 'Labor': 1, 'cosmonauts': 1, 'Washington-DC': 1, 'Abraham-Walkowitz': 1, 'Almanac-\"Archer\"': 1, 'Pony': 1, 'Peony': 1, 'Morocco': 1, 'barbershops': 1, 'Frank-Kleinholz': 1, 'Second-World-War': 1, 'USSR': 1, 'Stalingrad': 1, 'Abraham-Manievitch': 1, 'Caribbean': 1, 'revolutions': 1, '1917': 1, 'October-Revolution': 1, 'Bayville': 1, 'Temple': 1, 'Patchwork': 1, 'Cactus': 1, 'Blue and white porcelain': 1, 'Discovery-of-America': 1, 'The-Sun-Visits-Mayakovsky': 1, 'Bronx': 1, 'Hamlet': 1, 'Ophelia': 1, 'William-Shakespeare': 1, 'Dniester': 1, 'Sergei-Eisenstein': 1, 'Harlem-River': 1, 'Almanac-\"Raging-Parnassus\"': 1, 'Ex-Libris': 1, 'E.-F.-Gollerbach': 1, 'Cossack-Mamai': 1, 'Ukrainian-Mythology': 1, 'Swimming pool': 1, 'Labyrinth': 1, 'bathhouses': 1, 'moss': 1, 'Oar': 1, 'Canoeing': 1, 'Cathedral': 1, 'Ceremony': 1, 'Sea cave': 1, 'Palace': 1, 'Amaryllis belladonna': 1, 'Summit': 1, 'Massif': 1, 'Lugger': 1, 'Tagetes': 1, 'Tagetes patula': 1, 'Walkway': 1, 'Girder bridge': 1, 'Box girder bridge': 1, 'Steam frigate': 1, 'Escarpment': 1, 'Wheel': 1, 'Alley': 1, 'Infant bed': 1, 'Archaeological site': 1, 'Inlet': 1, 'Deciduous': 1, 'Train station': 1, 'Apricot': 1, 'Mabolo': 1, 'Bay': 1, 'Baked goods': 1, 'Poppy': 1, 'Mountain river': 1, 'Native Sowthistle': 1, 'perennial sowthistle': 1, 'Tibetan terrier': 1, 'Briard': 1, 'Lhasa apso': 1, 'Terrier': 1, 'Otterhound': 1, 'Transporter bridge': 1, 'Anemone': 1, 'Urban area': 1, 'Seafood': 1, 'Belly dance': 1, 'Tile flooring': 1, 'Domburg': 1, 'Netherlands': 1, 'Origami': 1, 'Room divider': 1, 'Place-de-la-Concorde': 1, 'Grazing': 1, 'Fence': 1, 'Broadway': 1, 'Square': 1, 'bears': 1, 'Bengal tiger': 1, 'Tiger': 1, 'Mandrill': 1, 'wars-and-battles': 1, 'Satan': 1, 'Fritillaria': 1, 'Coneflower': 1, 'Horse supplies': 1, 'Kettle': 1, 'Chopin': 1, 'flamingoes': 1, 'Love': 1, 'Folk dance': 1, 'Soccer ball': 1, 'flags': 1, 'carnival': 1, 'Oise': 1, 'Monstera deliciosa': 1, 'Violone': 1, 'Viol': 1, 'Bass violin': 1, 'Bowed string instrument': 1, 'Jean-Cocteau': 1, 'Leon-Bakst': 1, 'Chaim-Soutine': 1, 'Amedeo-Modigliani': 1, 'Violinist': 1, 'persian buttercup': 1, 'Allium': 1, 'Pitcher': 1, 'Judgement-of-Paris': 1, 'Red sky at morning': 1, 'Decanter': 1, 'Barware': 1, 'Mandarin orange': 1, 'Tangerine': 1, 'Hydrangeaceae': 1, 'Red hair': 1, 'Stallion': 1, 'Equestrianism': 1, 'Dressage': 1, 'Sardine': 1, 'Attalea speciosa': 1, 'Tomato': 1, 'Guitar': 1, 'Caffeine': 1, 'Wreath': 1, 'Blond': 1, 'Hair coloring': 1, 'Companion dog': 1, 'Puppy': 1, 'Meditation': 1, 'Stemware': 1, 'Meatball': 1, 'Ring-necked pheasant': 1, 'Black grouse': 1, 'Grouse': 1, 'Indian musical instruments': 1, 'Farmworker': 1, 'St.-Cecilia': 1, 'Susanna': 1, 'Domra': 1, 'Setar': 1, 'Spinet': 1, 'Technology': 1, 'Player piano': 1, 'Electronic device': 1, 'Leisure': 1, 'Construction paper': 1, 'guru': 1, 'Leda': 1, 'Leda-and-the-Swan': 1, 'Sunglasses': 1, 'Carpet': 1, 'hoopskirt': 1, 'King': 1, 'Clementine': 1, 'Watermelon': 1, 'Wood stain': 1, 'Wrapping paper': 1, 'Eggplant': 1, 'Nonbuilding structure': 1, 'Bowling pin': 1, 'Wrestling': 1, 'Cool': 1, 'Selling': 1, 'Place of worship': 1, 'Clown': 1, 'Family car': 1, 'Dhow': 1, 'Action-adventure game': 1, 'Rolling': 1, 'Historic house': 1, 'Handrail': 1, 'Shed': 1, 'Volga': 1, 'Kremlin': 1, 'St.-George': 1, 'Golden-Gates-of-Kiev': 1, 'Last-Judgment': 1, 'Clock': 1, 'Baba-Yaga': 1, 'Turkey Vulture': 1, 'California condor': 1, 'Loggerhead Shrike': 1, 'Swallow': 1, 'Red shouldered Hawk': 1, 'Ivy': 1, 'Argali': 1, 'bighorn': 1, \"Dall's sheep\": 1, 'Osprey': 1, 'Falconiformes': 1, 'Loon': 1, 'Musk deer': 1, 'Cedar Waxwing': 1, 'Yellow billed Cuckoo': 1, 'Bald eagle': 1, 'Accipitridae': 1, 'Kite': 1, 'Eastern Screech owl': 1, 'Western Screech owl': 1, 'Great horned owl': 1, 'Screech owl': 1, 'Eastern Whip poor will': 1, \"Cooper's Hawk\": 1, 'Sharp shinned Hawk': 1, 'New caledonian crow': 1, 'Nest': 1, 'Porcupine': 1, 'quail': 1, 'Snowy owl': 1, 'Parakeet': 1, 'Budgie': 1, 'Elk': 1, 'Reindeer': 1, 'Barren ground Caribou': 1, 'Magnolia Warbler': 1, 'Bonsai': 1, 'Red headed Woodpecker': 1, 'Ivory-billed woodpecker': 1, 'Black billed Magpie': 1, 'Eurasian magpie': 1, 'Crow-like bird': 1, 'Songbird': 1, 'Golden eagle': 1, 'brown hare': 1})\n",
            "Genre map dic : {'abstract': 0, 'allegorical painting': 1, 'animal painting': 2, 'cityscape': 3, 'flower painting': 4, 'illustration': 5, 'interior': 6, 'landscape': 7, 'marina': 8, 'mythological painting': 9, 'nude painting (nu)': 10, 'portrait': 11, 'religious painting': 12, 'self-portrait': 13, 'sketch and study': 14, 'still life': 15, 'symbolic painting': 16}\n",
            "Number of genre: 17\n",
            "abstract\n",
            "0\n",
            "---\n",
            "allegorical painting\n",
            "1\n",
            "---\n",
            "animal painting\n",
            "2\n",
            "---\n",
            "cityscape\n",
            "3\n",
            "---\n",
            "flower painting\n",
            "4\n",
            "---\n",
            "illustration\n",
            "5\n",
            "---\n",
            "interior\n",
            "6\n",
            "---\n",
            "landscape\n",
            "7\n",
            "---\n",
            "marina\n",
            "8\n",
            "---\n",
            "mythological painting\n",
            "9\n",
            "---\n",
            "nude painting (nu)\n",
            "10\n",
            "---\n",
            "portrait\n",
            "11\n",
            "---\n",
            "religious painting\n",
            "12\n",
            "---\n",
            "self-portrait\n",
            "13\n",
            "---\n",
            "sketch and study\n",
            "14\n",
            "---\n",
            "still life\n",
            "15\n",
            "---\n",
            "symbolic painting\n",
            "16\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACrWqAlPMsQs",
        "outputId": "44708984-3d13-425c-f480-920daeb5f3b6"
      },
      "source": [
        "\n",
        "print('-------------')\n",
        "print(len(all_painting_paths))\n",
        "print(all_painting_paths[3100:3105])\n",
        "print(len(all_labels))\n",
        "print(all_labels[3100:3105])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------\n",
            "10482\n",
            "['/mydrive/GAN/Data/gustav-klimt/horticultural-landscape-with-a-hilltop.jpg', '/mydrive/GAN/Data/gustav-klimt/apple-tree-i.jpg', '/mydrive/GAN/Data/gustav-klimt/buchenhain.jpg', '/mydrive/GAN/Data/gustav-klimt/quiet-pond-in-the-park-of-appeal.jpg', '/mydrive/GAN/Data/gustav-klimt/flower-garden-1907.jpg']\n",
            "10482\n",
            "[7, 7, 7, 7, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHe-s9gSLSux",
        "outputId": "cfc20cd4-0d57-4bd1-9af8-85844a998546"
      },
      "source": [
        "if BY_ARTIST:\n",
        "    NUM_CLASSES  = 22\n",
        "if BY_GENRE:\n",
        "    NUM_CLASSES = 17\n",
        "BATCH_SIZE = 64\n",
        "fixed_labels  = torch.tensor(list(np.arange(0,NUM_CLASSES))*6)[:BATCH_SIZE] # to have dim 64 \n",
        "print(fixed_labels)\n",
        "print('Lenght fixed labels :' , len(fixed_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  0,\n",
            "         1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  0,  1,\n",
            "         2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  0,  1,  2,\n",
            "         3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
            "Lenght fixed labels : 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e25MOZQ6qa4c",
        "outputId": "313e1de8-023b-48bb-b899-638d88adda2d"
      },
      "source": [
        "l=[1,2,3,4,5,6,7,8,9,10]\n",
        "print(sum(l[:5])/5)\n",
        "print(sum(l[-5:])/5)\n",
        "print(np.mean(l[:5]))\n",
        "print(np.mean(l[-5:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0\n",
            "8.0\n",
            "3.0\n",
            "8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmOWQVk3hpcV"
      },
      "source": [
        "##  TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2MZNNXJ2XJ8"
      },
      "source": [
        "# Hyperparameters etc.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 1.0e-4\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 64\n",
        "CHANNELS_IMG = 3\n",
        "Z_DIM = 124\n",
        "NUM_EPOCHS_START = 3240\n",
        "NUM_EPOCHS = NUM_EPOCHS_START + 300\n",
        "FEATURES_CRITIC = 64\n",
        "FEATURES_GEN = 64\n",
        "CRITIC_ITERATIONS = 5\n",
        "GENERATOR_ITERATIONS = 1\n",
        "LAMBDA_GP = 10 # gradient penalty\n",
        "GENERATOR_EMBEDDING  = NUM_CLASSES \n",
        "NUM_DISPLAY = 500\n",
        "SAVE_EPOCH = 50\n",
        "\n",
        "\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "date = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "\n",
        "transformations = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# -- dataset dataloader\n",
        "# --- artist \n",
        "dataset = Art_Dataset(all_painting_paths, all_labels, transform=transformations)\n",
        "\n",
        "loader = DataLoader(dataset,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jyXa1SMRoUWf"
      },
      "source": [
        "# # --- Mnist \n",
        "# dataset = datasets.MNIST(root=\"dataset/\", transform=transformations, download=True)\n",
        "# loader = DataLoader(\n",
        "#     dataset,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     shuffle=True,\n",
        "# )\n",
        "\n",
        "# initialize gen and disc, note: discriminator should be called critic,\n",
        "# according to WGAN paper (since it no longer outputs between [0, 1])\n",
        "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GENERATOR_EMBEDDING).to(device)\n",
        "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC, NUM_CLASSES,IMG_SIZE).to(device)\n",
        "\n",
        "# initializate optimizer\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
        "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
        "\n",
        "ckpt_path  = f'/mydrive/GAN/Models/by_genre/2021_09_28_WcGAN_BYGENRE_v1_{NUM_EPOCHS_START}_latest.pkl'\n",
        "#ckpt_path = None\n",
        "if ckpt_path is not None:\n",
        "    ckpt = torch.load(ckpt_path)\n",
        "    gen.load_state_dict(ckpt['gen_state_dict'])\n",
        "    critic.load_state_dict(ckpt['disc_state_dict'])\n",
        "    opt_gen.load_state_dict(ckpt['gen_optimizer_state_dict'])\n",
        "    opt_critic.load_state_dict(ckpt['disc_optimizer_state_dict'])\n",
        "else: \n",
        "    initialize_weights(gen)\n",
        "    initialize_weights(critic)\n",
        "\n",
        "\n",
        "# for tensorboard plotting\n",
        "fixed_noise = torch.randn(BATCH_SIZE , Z_DIM, 1, 1).to(device)\n",
        "fixed_labels  = torch.tensor(list(np.arange(0,NUM_CLASSES))*6)[:BATCH_SIZE].to(device)\n",
        "#fixed_labels  = torch.tensor(list(np.arange(0,NUM_CLASSES))*6+[0,0,0,0]).to(device) # to have dim 64 \n",
        "\n",
        "writer  =  SummaryWriter(log_dir)\n",
        "writer_real = SummaryWriter(os.path.join(log_dir,'real'))\n",
        "writer_fake = SummaryWriter(os.path.join(log_dir,'fake'))\n",
        "\n",
        "gen.train()\n",
        "critic.train()\n",
        "\n",
        "generator_losses = []\n",
        "critic_losses =[]\n",
        "\n",
        "step = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS_START, NUM_EPOCHS):\n",
        "    for batch_idx, (real, labels, path) in enumerate(loader):\n",
        "        real = real.to(device)\n",
        "        cur_batch_size = real.shape[0]\n",
        "        labels = labels.to(device)\n",
        "        mean_iteration_critic_loss =0\n",
        "        mean_iteration_generator_loss=0\n",
        "\n",
        "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
        "        # equivalent to minimizing the negative of that\n",
        "        for _ in range(CRITIC_ITERATIONS):\n",
        "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
        "            fake = gen(noise, labels)\n",
        "            critic_real = critic(real, labels).reshape(-1)\n",
        "            critic_fake = critic(fake, labels).reshape(-1)\n",
        "            gp = gradient_penalty(critic,labels, real, fake, device=device)\n",
        "            loss_critic = (\n",
        "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n",
        "            )\n",
        "            critic.zero_grad()\n",
        "            # Keep track of the average critic loss in this batch\n",
        "            mean_iteration_critic_loss += loss_critic.item() / CRITIC_ITERATIONS\n",
        "            loss_critic.backward(retain_graph=True)\n",
        "            opt_critic.step()\n",
        "\n",
        "        critic_losses += [mean_iteration_critic_loss]\n",
        "\n",
        "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
        "        for _ in range(GENERATOR_ITERATIONS):\n",
        "            gen_fake = critic(fake, labels).reshape(-1)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "            gen.zero_grad()\n",
        "            # Keep track of the average critic loss in this batch\n",
        "            mean_iteration_generator_loss += loss_gen.item() / GENERATOR_ITERATIONS\n",
        "            loss_gen.backward()\n",
        "            opt_gen.step()\n",
        "\n",
        "        generator_losses += [mean_iteration_generator_loss]\n",
        "\n",
        "\n",
        "        # Print losses occasionally and print to tensorboard\n",
        "        if step % NUM_DISPLAY == 0 and step > 0:\n",
        "            gen_mean_loss = sum(generator_losses[-NUM_DISPLAY:]) / NUM_DISPLAY \n",
        "            crit_mean_loss = sum(critic_losses[-NUM_DISPLAY:]) / NUM_DISPLAY \n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{NUM_EPOCHS}] | Step {step} | Batch {batch_idx}/{len(loader)} \\\n",
        "                  Loss G: {gen_mean_loss:.4f}, loss D: {crit_mean_loss:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # print('fixed_noise shape :', fixed_noise.shape)\n",
        "                # print('fixed_labels shape :', fixed_labels.shape)\n",
        "                #fake = gen(fixed_noise, fixed_labels)\n",
        "                fake = gen(noise, labels)\n",
        "                # take out (up to) 32 examples\n",
        "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
        "\n",
        "                # -- writer\n",
        "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
        "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
        "\n",
        "                # -- write to writer\n",
        "                writer.add_scalar(\"loss_gen\", gen_mean_loss, step)\n",
        "                writer.add_scalar(\"loss_critic\", crit_mean_loss, step)\n",
        "\n",
        "                print('--real images ---')\n",
        "                show_tensor_images(real)\n",
        "                print('--fake images ---')\n",
        "                show_tensor_images(fake)\n",
        "\n",
        "                step_bins = 20\n",
        "                num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "                plt.plot(\n",
        "                    range(num_examples // step_bins), \n",
        "                    torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                    label=\"Generator Loss\"\n",
        "                )\n",
        "                plt.plot(\n",
        "                    range(num_examples // step_bins), \n",
        "                    torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                    label=\"Discriminator Loss\"\n",
        "                )\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "                print('saving images generated with fixed noise')\n",
        "                save_samples(step, epoch, fixed_noise, fixed_labels, stats, sample_dir = sample_dir, resize_size=128, show=False)    \n",
        "       \n",
        "        step += 1\n",
        "    # -- save the model at the end of the epoch \n",
        "    if epoch % SAVE_EPOCH == 0 and epoch > 0:\n",
        "        torch.save({\n",
        "        'gen_state_dict': gen.state_dict(),\n",
        "        'disc_state_dict': critic.state_dict(),\n",
        "        'gen_optimizer_state_dict': opt_gen.state_dict(),\n",
        "        'disc_optimizer_state_dict': opt_critic.state_dict(),\n",
        "        }, os.path.join(model_save_DIR, f'{date}_WcGAN_BYGENRE_v1_{epoch}_latest.pkl'))\n",
        "\n",
        "        save_samples(len(loader), epoch,fixed_noise,fixed_labels, stats,sample_dir = sample_dir, resize_size=128, show=True)  \n",
        "\n",
        "        print('------------------------------------------------------------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35YzcP6RoUfH"
      },
      "source": [
        "writer.flush()\n",
        "writer_real.flush()\n",
        "writer_fake.flush()\n",
        "writer_real.close()\n",
        "writer_fake.close()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND0nV9htYBxS"
      },
      "source": [
        "log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFTrlJs8oElc"
      },
      "source": [
        "## tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWco0KQ0oUh3"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=/content/gdrive/MyDrive/GAN/logs/Wcgan/art_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lId5vJKodWcv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcupMZqRqbak"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/GAN/logs/Wcgan/art_2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6a5OIcxoUlA"
      },
      "source": [
        "#-- %reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cme-ikvboUoL"
      },
      "source": [
        "rferf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5ruKkw8oXb0"
      },
      "source": [
        "## OLD TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Pjd6ooe4_O"
      },
      "source": [
        "\n",
        "# Hyperparameters etc.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 1e-4\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS_IMG = 1\n",
        "Z_DIM = 124\n",
        "NUM_EPOCHS = 2\n",
        "FEATURES_CRITIC = 64\n",
        "FEATURES_GEN = 64\n",
        "CRITIC_ITERATIONS = 5\n",
        "LAMBDA_GP = 10\n",
        "IMG_SIZE= 64\n",
        "NUM_CLASSES = 10\n",
        "GENERATOR_EMBEDDING  = 10\n",
        "\n",
        "transformations = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(IMAGE_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transformations, download=True)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# initialize gen and disc, note: discriminator should be called critic,\n",
        "# according to WGAN paper (since it no longer outputs between [0, 1])\n",
        "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GENERATOR_EMBEDDING).to(device)\n",
        "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC, NUM_CLASSES,IMG_SIZE).to(device)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(critic)\n",
        "\n",
        "# initializate optimizer\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
        "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
        "\n",
        "# for tensorboard plotting\n",
        "fixed_noise = torch.randn(BATCH_SIZE , Z_DIM, 1, 1).to(device)\n",
        "fixed_labels  = torch.tensor(list(np.arange(0,NUM_CLASSES))*6+[0,0,0,0]).to(device) # to have dim 64 \n",
        "writer_real = SummaryWriter(f\"logs/GAN_MNIST/real\")\n",
        "writer_fake = SummaryWriter(f\"logs/GAN_MNIST/fake\")\n",
        "step = 0\n",
        "# -- save DIR   \n",
        "DIR = '/mydrive/GAN' \n",
        "sample_dir = os.path.join(DIR,'generated','Wcgan','art_2')\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "model_save_DIR = os.path.join(DIR,'Models','art_2')\n",
        "\n",
        "\n",
        "gen.train()\n",
        "critic.train()\n",
        "\n",
        "generator_losses = []\n",
        "critic_losses =[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Target labels not needed! <3 unsupervised\n",
        "    for batch_idx, (real, labels) in enumerate(loader):\n",
        "        real = real.to(device)\n",
        "        cur_batch_size = real.shape[0]\n",
        "        labels = labels.to(device)\n",
        "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
        "        # equivalent to minimizing the negative of that\n",
        "        for _ in range(CRITIC_ITERATIONS):\n",
        "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
        "            fake = gen(noise, labels)\n",
        "            critic_real = critic(real, labels).reshape(-1)\n",
        "            critic_fake = critic(fake, labels).reshape(-1)\n",
        "            gp = gradient_penalty(critic,labels,  real, fake, device=device)\n",
        "            loss_critic = (\n",
        "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n",
        "            )\n",
        "            critic.zero_grad()\n",
        "            loss_critic.backward(retain_graph=True)\n",
        "            opt_critic.step()\n",
        "            critic_losses += [loss_critic.item()]\n",
        "\n",
        "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
        "        gen_fake = critic(fake, labels).reshape(-1)\n",
        "        loss_gen = -torch.mean(gen_fake)\n",
        "        gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        \n",
        "        generator_losses += [loss_gen.item()]\n",
        "        \n",
        "\n",
        "        # Print losses occasionally and print to tensorboard\n",
        "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
        "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # print('fixed_noise shape :', fixed_noise.shape)\n",
        "                # print('fixed_labels shape :', fixed_labels.shape)\n",
        "                fake = gen(fixed_noise, fixed_labels)\n",
        "                # take out (up to) 32 examples\n",
        "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
        "\n",
        "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
        "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
        "\n",
        "                print('--real images ---')\n",
        "                show_tensor_images(real)\n",
        "                print('--fake images ---')\n",
        "                show_tensor_images(fake)\n",
        "\n",
        "                step_bins = 20\n",
        "                num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "                plt.plot(\n",
        "                    range(num_examples // step_bins), \n",
        "                    torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                    label=\"Generator Loss\"\n",
        "                )\n",
        "                plt.plot(\n",
        "                    range(num_examples // step_bins), \n",
        "                    torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                    label=\"Discriminator Loss\"\n",
        "                )\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "                print('saving images generated with fixed noise')\n",
        "                save_samples(step, epoch, fixed_noise, fixed_labels,sample_dir = sample_dir, resize_size=128, show=False)  \n",
        "\n",
        "            step += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}